# FirstLabAI
## Определение фейковых новостей с использованием методов анализа текста

### 1. Постановка задачи, Цель работы. Теоретическая база

#### Постановка задачи

Задача заключается в классификации новостей как "фейк" или "реальная". Необходимо реализовать и обучить нейронную сеть для решения задачи бинарной классификации текстов.

**Требования:**
1.  Собрать или использовать готовый датасет новостей, размеченный по категориям «фейк» / «реальная новость» (например, FakeNewsNet, LIAR, Kaggle Fake News Dataset).
2.  Выполнить предварительную обработку текстов.
3.  Преобразовать тексты в числовое представление (векторы): TF-IDF, Bag-of-Words, Word2Vec или Sentence Transformers.
4.  Обучить модель классификации.
5.  Оценить качество модели по метрикам: Precision, Recall, F1-score, ROC-AUC.
6.  Проанализировать наиболее значимые признаки (слова или выражения), влияющие на решение модели.

**Датасет:** Собираем датасет самостоятельно. Парсим реальные новости и генерируем фейковые новости с помощью языковой модели. Язык русский.
**Векторы:** LLM (Sentence Transformers)
**Модель:** zero-shot-classification, few-shot-classification

#### Цель работы

Научиться реализовывать алгоритмы глубокого обучения, в частности:

*   Работать с текстовыми датасетами
*   Применять предобученные языковые модели (LLM) для векторизации
*   Сравнивать различные подходы к классификации (zero-shot, обучение с нуля)
*   Оценивать качество моделей с помощью метрик Precision, Recall, F1-score, ROC-AUC
*   Анализировать признаки, влияющие на принятие решения моделью

#### Теоретическая база

**Sentence Transformers (LLM)**
Sentence Transformers — это библиотека, позволяющая использовать предобученные трансформеры (например, BERT, RoBERTa, DistilBERT) для создания фиксированных векторных представлений (эмбеддингов) предложений или абзацев. Эти эмбеддинги отражают семантическое значение текста и могут использоваться для задач классификации, кластеризации, поиска и т.д. В работе используется для векторизации текстов новостей.

**Zero-Shot и Few-Shot Classification**
*   **Zero-Shot Classification:** Модель способна классифицировать текст в категории, которые *не видела* во время своего обучения, на основе описания этих категорий и входного текста. Требует предобученной модели, понимающей смысл текста.
*   **Few-Shot Classification:** Модель обучается (или адаптируется) к новой задаче с *очень малым количеством* примеров. В работе представлен как заготовка.

**Logistic Regression**
Логистическая регрессия — это статистическая модель, используемая для задач бинарной или многоклассовой классификации. Несмотря на свою относительную простоту, она часто показывает хорошие результаты, особенно когда признаки (например, эмбеддинги из Sentence Transformers) хорошо отделяют классы. В работе используется как обучаемая модель поверх эмбеддингов.

**Transfer Learning (Дообучение)**
Transfer Learning — это техника, при которой модель, предобученная на большом датасете, адаптируется для решения новой задачи. В контексте Zero-Shot и Few-Shot классификации, это означает использование *предобученной* модели (например, BERT, RoBERTa), которая уже "знает" структуру языка, для решения новой задачи без дополнительного обучения (Zero-Shot) или с минимальным обучением (Few-Shot). В обучаемой модели LogisticRegression используются эмбеддинги, извлеченные предобученной моделью Sentence Transformers.

**Метрики качества**
*   **Accuracy (Точность):** Доля правильно предсказанных примеров среди всех примеров.
    *   `Accuracy = (TP + TN) / (TP + TN + FP + FN)`
*   **Precision (Точность положительного класса):** Доля правильно предсказанных положительных примеров среди всех *предсказанных* положительных.
    *   `Precision = TP / (TP + FP)`
*   **Recall (Полнота положительного класса):** Доля правильно предсказанных положительных примеров среди всех *реальных* положительных.
    *   `Recall = TP / (TP + FN)`
*   **F1-Score:** Гармоническое среднее Precision и Recall.
    *   `F1 = 2 * (Precision * Recall) / (Precision + Recall)`
*   **ROC-AUC (Area Under the ROC Curve):** Метрика, оценивающая качество бинарного классификатора при различных порогах. Чем ближе к 1.0, тем лучше.

### 2. Описание разработанной системы

#### Алгоритмы и принципы работы

##### 2.1 Подготовка данных

*   **Сбор датасета:**
    *   Реальные новости: Используется библиотека `feedparser` для получения новостей из RSS-ленты (например, BBC News).
    *   Фейковые новости: Реализована генерация с помощью языковой модели `gpt2` через библиотеку `transformers`. Модель получает "подсказку" (промпт), например, "Breaking News: A recent study claims that...", и генерирует продолжение, которое считается фейковой новостью.
*   **Разделение данных:** Датасет состоит из равного количества реальных и фейковых новостей (например, 5 + 5 = 10).
*   **Предварительная обработка текста:** Тексты (заголовки и содержание) очищаются от HTML-тегов.

##### 2.2 Архитектура модели

*   **Векторизация (LLM):** Используется `sentence-transformers` (например, `all-MiniLM-L6-v2`) для преобразования текстов в числовые векторы (эмбеддинги).
*   **Zero-Shot Classifier:** Использует `transformers.pipeline` с предобученной моделью (`cointegrated/rubert-base-cased-nli-threeway`) для классификации без обучения на конкретном датасете.
*   **Обучаемая модель (Logistic Regression):** Использует эмбеддинги, полученные из `sentence-transformers`, как признаки для обучения модели `LogisticRegression` с помощью библиотеки `scikit-learn`.

##### 2.3 Процесс обучения

*   Для обучаемой модели `LogisticRegression`:
    *   **Обучение:** Модель обучается на эмбеддингах текстов и их метках (0 - фейк, 1 - реальная).
    *   **Тестирование:** Модель оценивается на том же датасете (в текущей реализации).
*   Для `Zero-Shot Classifier`:
    *   **Классификация:** Модель применяется к текстам без предварительного обучения на них.

##### 2.4 Оценка качества

*   **Метрики:** Вычисляются `accuracy`, `precision`, `recall`, `f1`, `roc_auc` с помощью `scikit-learn`.
*   **Анализ признаков:** Для обучаемой модели `LogisticRegression` анализируются коэффициенты, чтобы понять, какие *измерения* эмбеддинга наиболее важны для принятия решения.

### 3. Результаты работы и тестирования системы

#### 3.1 Параметры эксперимента

*   **Датасет:** Синтетический (5 реальных, 5 сгенерированных `gpt2`).
*   **Векторизация:** `sentence-transformers` (all-MiniLM-L6-v2).
*   **Zero-Shot модель:** `cointegrated/rubert-base-cased-nli-threeway`.
*   **Обучаемая модель:** `LogisticRegression`.
*   **Метрики:** `accuracy`, `precision`, `recall`, `f1`, `roc_auc`.

#### 3.2 Результаты

*   **Zero-Shot Classifier Metrics:**
    *   `accuracy: 0.5000`
    *   `precision: 0.5000`
    *   `recall: 0.4000`
    *   `f1: 0.4444`
    *   `roc_auc: 0.6400`
*   **Trained Classifier Metrics (на тренировочном датасете):**
    *   `accuracy: 1.0000`
    *   `precision: 1.0000`
    *   `recall: 1.0000`
    *   `f1: 1.0000`
    *   `roc_auc: 1.0000` (Переобучение)

### 4. Выводы по работе

#### 4.1 Достигнутые результаты

*   Реализован пайплайн обработки текста для задачи классификации фейковых новостей.
*   Интегрированы `transformers` и `sentence-transformers` для генерации и векторизации текста.
*   Реализованы `ZeroShotClassifier` и обучаемая `LogisticRegression`.
*   Оценено качество моделей с использованием метрик.

#### 4.2 Наблюдения

*   **Эффективность Zero-Shot:** Zero-shot модель показала умеренные результаты на синтетическом датасете, что более реалистично, чем на заглушках.
*   **Переобучение:** Обучаемая модель показывает идеальные метрики на тренировочном датасете (переобучение).
*   **Генерация фейков:** Реализована *настоящая* генерация с помощью `gpt2`, что лучше, чем заглушки.

#### 4.3 Возможные улучшения

*   **Датасет:** Использовать *настоящий* датасет с размеченными фейками и реальными новостями.
*   **Few-Shot:** Реализовать полноценный few-shot подход.
*   **GPU:** Настроить использование GPU для ускорения вычислений.
*   **Дополнительная аугментация:** Использование более сложных техник аугментации текста.
*   **Обработка дисбаланса классов:** Применение техник для работы с несбалансированными данными.

### Инструкция по запуску

#### Требования

*   Python 3.8+
*   PyTorch 2.0+
*   transformers
*   sentence-transformers
*   scikit-learn
*   feedparser

#### Установка зависимостей

```bash
pip install -r requirements.txt
```

#### Запуск

```bash
python task_1/main.py
```

#### Результаты

После выполнения скрипта будут выведены метрики для `ZeroShotClassifier` и обучаемой `LogisticRegression`.
