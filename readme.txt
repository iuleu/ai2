Задача 1: Определение фейковых новостей
Датасет: Собран самостоятельно. Реальные новости парсятся из RSS-ленты, фейковые генерируются заглушками.
Векторы: Использованы Sentence Transformers (LLMVectorizer) для преобразования текстов в эмбеддинги.
Модель: Реализованы ZeroShotClassifier, FewShotClassifier (заготовка) и обучаемая LogisticRegression.
Оценка: Вычисляются метрики accuracy, precision, recall, f1, roc_auc. Проводится анализ признаков для обучаемой модели.
Результат: Пайплайн работает на синтетических данных.

Задача 2: Классификация видео
Датасет: HowTo100M | Health.
Попытка реализации: Написан скрипт для фильтрации и загрузки видео.
Проблема: Оригинальный датасет HowTo100M (~150 ГБ) не был скачан из-за ограничений по дисковому пространству. Реальное подмножество "Health" не создано.
Векторы: videomae.
Попытка реализации: Добавлен VideoMAEFeatureExtractor.
Проблема: Модель VideoMAE не найдена в timm и не загружена через torch.hub. Использован fallback на vit_base_patch16_224 из timm.
Модель: Дообучаем.
Попытка реализации: Созданы model.py, trainer.py.
Проблема: Дообучение невозможно без реального датасета. Модели обучаются с нуля на синтетических данных.
Результат: Пайплайн не запущен на целевом датасете. Реализована заготовка с fallback моделью.